{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070a84d-82fa-461c-b24a-bc664dd3ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6f3fb-3d2e-4ae6-8d88-5af793683b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading my the dataset\n",
    "df = pd.read_csv('yield_df.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48418a88-1ae5-4d81-8779-4010e5f9046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e44cf-c12b-4df7-b356-0b678e2e55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c979cb-ca9c-4133-abe0-d1277dd484ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8397eb-360c-485b-b64a-e6ea32400570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7a279-19ac-4536-a88e-69f97a75d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show various statistical depth\n",
    "def show_statistical_depth():\n",
    "    \"\"\"\n",
    "    Shows statistical depth including mean, median, standard deviation, skewness, kurtosis, correlation matrix, and basic descriptive statistics.\n",
    "    \"\"\"\n",
    "    numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "    \n",
    "    # Calculatting major variables\n",
    "    mean = numeric_df.mean()\n",
    "    median = numeric_df.median()\n",
    "    std_dev = numeric_df.std()\n",
    "    skewness = numeric_df.skew()\n",
    "    kurtosis = numeric_df.kurtosis()\n",
    "    \n",
    "    # Display of major variables\n",
    "    print(\"Mean:\\n\", mean)\n",
    "    print(\"\\nMedian:\\n\", median)\n",
    "    print(\"\\nStandard Deviation:\\n\", std_dev)\n",
    "    print(\"\\nSkewness:\\n\", skewness)\n",
    "    print(\"\\nKurtosis:\\n\", kurtosis)\n",
    "show_statistical_depth()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eee05-986d-4dd1-9545-66a54eaae843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to plot a bar chart for crop items with their counts\n",
    "def plot_categorical_graph(df):\n",
    "    \"\"\"\n",
    "    Plot a bar chart to visualize the count for each crop item.\n",
    "    :param df: pd.DataFrame - The input dataset\n",
    "    \"\"\"\n",
    "    # Get the count of each 'Item'\n",
    "    item_counts = df['Item'].value_counts()\n",
    "\n",
    "    # Create a figure with a specific size\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    item_counts.plot(kind='bar', color='purple')\n",
    "    plt.title('Crop Item Count by Category')\n",
    "    plt.xlabel('Crop Item')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "plot_categorical_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049c298-dff5-4297-a7f9-dc6ba02de576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features for clustering from my dataset and standadise please note this code will have some predictions\n",
    "features = ['average_rain_fall_mm_per_year', 'avg_temp']\n",
    "df_selected = df[features]\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_selected)\n",
    "\n",
    "# Determine the optimal number of clusters using the silhouette score\n",
    "range_n_clusters = range(2, 6)\n",
    "best_score = -1\n",
    "best_k = 0\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(df_scaled)\n",
    "    score = silhouette_score(df_scaled, cluster_labels)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = n_clusters\n",
    "\n",
    "# Perform clustering with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# to create a custom colormap for plotting\n",
    "colours = plt.cm.Set1(np.linspace(0, 1, best_k))\n",
    "cmap = ListedColormap(colours)\n",
    "\n",
    "# Function to perform k-means clustering and plot the clusters with predictions\n",
    "def kmeans_clustering():\n",
    "    \"\"\"\n",
    "    Performs k-means clustering and plots the clusters with predictions.\n",
    "    \"\"\"\n",
    "    # Back scale the cluster centers to original scale\n",
    "    cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "    \n",
    "    # here i will try to predict new points and attach them to an appropriate groups\n",
    "    new_points = [[1500, 16], [1600, 17], [1700, 18]]\n",
    "    new_points_df = pd.DataFrame(new_points, columns=['average_rain_fall_mm_per_year', 'avg_temp'])\n",
    "    new_points_normalized = scaler.transform(new_points_df)\n",
    "    \n",
    "    new_clusters = kmeans.predict(new_points_normalized)\n",
    "    new_points_df['Cluster'] = new_clusters\n",
    "    \n",
    "    plt.figure(figsize=(10, 7), dpi=144)\n",
    "    \n",
    "    # here is code for oraginal data\n",
    "    sns.scatterplot(data=df, x='average_rain_fall_mm_per_year', y='avg_temp', hue='Cluster', palette='viridis', alpha=1, edgecolor='w', s=20)\n",
    "\n",
    "    # here is code for predicted data\n",
    "    sns.scatterplot(data=new_points_df, x='average_rain_fall_mm_per_year', y='avg_temp', hue='Cluster', palette='viridis', alpha=1, marker='X', s=25, edgecolor='w')\n",
    "\n",
    "    # Plot of cluster centers\n",
    "    for i, center in enumerate(cluster_centers):\n",
    "        plt.scatter(center[0], center[1], s=100, c='red', marker='X', label=f'Centroid {i+1}')\n",
    "    \n",
    "    plt.title('K-Means Clustering with Cluster Centers and Predictions', color='red')\n",
    "    plt.xlabel('Average Rainfall (mm/year)')\n",
    "    plt.ylabel('Average Temperature (Â°C)')\n",
    "    \n",
    "    # Legend for cluster centers and new points\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    \n",
    "    # Here I'm adding centroid labels manually to avoid duplicates\n",
    "    by_label.update({f'Centroid {i+1}': handles[-(i+1)] for i in range(len(cluster_centers))})\n",
    "    if by_label:\n",
    "        plt.legend(by_label.values(), by_label.keys())\n",
    "        silhouette_avg = silhouette_score(df_scaled, df['Cluster'])\n",
    "    print(f'Silhouette Score: {silhouette_avg:.2f}')\n",
    "    plt.xticks(rotation=45, fontsize=10, color='orange')\n",
    "    plt.yticks(fontsize=10, color='orange')\n",
    "    plt.savefig('kmeans.png')\n",
    "    plt.show()\n",
    "kmeans_clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17eed4-565f-4a7a-9dce-0b0f17add293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the heatmap fuction for number columns please note unamed is just the count of data\n",
    "def show_correlation_matrix():\n",
    "    # Select only numeric columns\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Create the correlation matrix and plotting\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='cividis', fmt='.2f', \n",
    "                xticklabels=corr_matrix.columns, yticklabels=corr_matrix.columns, cbar_kws={'label': 'Correlation Coefficient'})\n",
    "    plt.title('Heatmap of Correlation Matrix ', fontsize=12)\n",
    "    plt.xlabel('Features', fontsize=10)\n",
    "    plt.ylabel('Features', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('correlation_matrix.png')\n",
    "    plt.show()\n",
    "show_correlation_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b684a-806d-46be-a641-18483539ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the numerical columns for clustering\n",
    "numerical_columns = ['hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp']\n",
    "df_numerical = df[numerical_columns]\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_numerical)\n",
    "\n",
    "# Elbow method to determine the optimal number of clusters\n",
    "inertia = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fab39f-e224-4899-87f4-d29a4bfef9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will choose years and yields to try and predict with use of actaul data\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
    "df['hg/ha_yield'] = pd.to_numeric(df['hg/ha_yield'], errors='coerce')\n",
    "df = df.dropna(subset=['Year', 'hg/ha_yield'])\n",
    "\n",
    "# the exponential function for fitting\n",
    "def exponential(x, n0, g):\n",
    "    return n0 * np.exp(g * x)\n",
    "\n",
    "# Normalize year data for better fitting\n",
    "xdata = df['Year'].values - min(df['Year'].values)\n",
    "ydata = df['hg/ha_yield'].values\n",
    "p, cov = curve_fit(exponential, xdata, ydata, p0=(1e4, 0.02))\n",
    "sigma = np.sqrt(np.diag(cov))\n",
    "future_years = np.arange(min(df['Year']), max(df['Year']) + 10)\n",
    "x_future = future_years - min(df['Year'])\n",
    "future_predictions = exponential(x_future, *p)\n",
    "\n",
    "# Here i will make some prediction \n",
    "sample_params = multivariate_normal.rvs(mean=p, cov=cov, size=1000)\n",
    "future_uncertainties = [np.std(exponential(year, *sample_params.T)) for year in x_future]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(df['Year'], df['hg/ha_yield'], label='Actual Data', color='blue')\n",
    "plt.plot(future_years, future_predictions, label='Exponential Fit', color='green')\n",
    "plt.fill_between(\n",
    "    future_years,\n",
    "    future_predictions - future_uncertainties,\n",
    "    future_predictions + future_uncertainties,\n",
    "    color='red', alpha=0.7, label='Confidence Interval')\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Yield (hg/ha)', fontsize=12)\n",
    "plt.title('Yield Analysis and Prediction with Uncertainty', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(f\"Fit Parameters: N0 = {p[0]:.2f} Â± {sigma[0]:.2f}, g = {p[1]:.4f} Â± {sigma[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
